{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnews_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-gp/NLP/blob/master/cnews_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP87jYz89mu-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from tensorflow import keras as kr\n",
        "import torch.utils.data as Data\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCrAhmNdbVXF",
        "outputId": "fa21b4d9-9fa6-4183-85bb-9379c4004569"
      },
      "source": [
        "# 数据文件设置\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive\")\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/BI_core/BI_core_L9\")\n",
        "\n",
        "train_file = './cnews.train.txt'\n",
        "test_file = './cnews.test.txt'\n",
        "val_file = './cnews.val.txt'\n",
        "vocab_file = './cnews.vocab.txt'\n",
        "sample_file = \"./cnews.train.sample.txt\"\n",
        "\n",
        "sample_size = 10\n",
        "batch_size = 200\n",
        "epoch = 100"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPbZCTxQd24k"
      },
      "source": [
        "# 得到采样训练数据\n",
        "def get_train_sample():\n",
        "  sample = {}\n",
        "  #采样数据\n",
        "  with open(train_file,\"r\",encoding=\"UTF-8\") as file:\n",
        "    for line in file.readlines():\n",
        "      #print(line)\n",
        "      label,text = line.split(\"\\t\")\n",
        "      if label in sample:\n",
        "        if len(sample[label]) < sample_size:\n",
        "          sample[label].append(text)\n",
        "      else:\n",
        "        sample[label] = [text]\n",
        "  #print(sample)\n",
        "  #保存采样数据\n",
        "  with open(sample_file,\"w\",encoding=\"UTF-8\") as file:\n",
        "    for label,texts in sample.items():\n",
        "      for text in texts:\n",
        "        file.write((\"{}\\t{}\".format(label,text)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgsD0CPY9mvA"
      },
      "source": [
        "# 读取词汇表文件，转化为列表，字典。\n",
        "def read_words():\n",
        "  words = []\n",
        "  with open(vocab_file,'r',encoding='UTF_8',errors='ignore') as file:\n",
        "    for word in file.readlines():\n",
        "      word = word.strip()\n",
        "      if word not in words:\n",
        "        words.append(word)\n",
        "  return words,dict(zip(words,range(len(words))))    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsOx5Ke9mvA"
      },
      "source": [
        "# 将类别转化为列表和字典，共10个类别\n",
        "def read_cates():\n",
        "  cates = []\n",
        "  with open(sample_file,\"r\",encoding=\"UTF-8\") as file:\n",
        "    for line in file.readlines():\n",
        "      cate,_ = line.split(\"\\t\")\n",
        "      if cate not in cates:\n",
        "        cates.append(cate)\n",
        "  return cates,dict(zip(cates,range(len(cates)))),dict(zip(range(len(cates)),cates))  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuE9AjOz9mvA"
      },
      "source": [
        "# 将文本处理为待训练数据\n",
        "def process_file(filename,word_to_id,cat_to_id,max_length=200):\n",
        "  contents,labels = [],[]\n",
        "  with open(filename,'r',encoding='UTF-8',errors = 'ignore') as file:\n",
        "    for line in file:\n",
        "      try:\n",
        "        label,content = line.strip().split('\\t')\n",
        "        if content:\n",
        "          contents.append(content)\n",
        "          labels.append(label)\n",
        "      except:\n",
        "        pass       \n",
        "  data_id,label_id = [],[]\n",
        "  for i in range(len(contents)):\n",
        "    #将每句话id化\n",
        "    data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n",
        "    label_id.append(cat_to_id[labels[i]])\n",
        "  #print(data_id)\n",
        "  #print(label_id)        \n",
        "  #使用keras提供的pad_sequences将文本pad为固定长度\n",
        "  x_pad = kr.preprocessing.sequence.pad_sequences(data_id,max_length)\n",
        "  y_pad = kr.utils.to_categorical(label_id,num_classes = len(cat_to_id))#将标签转换为one_hot表示\n",
        "  return x_pad,y_pad"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AxuO7Yb9mvA"
      },
      "source": [
        "# 构建RNN模型\n",
        "class TextRNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(TextRNN,self).__init__()\n",
        "    self.embedding = nn.Embedding(len(words),64) #输入维度4998，word的数量，输出64维\n",
        "    #双向GRU网络\n",
        "    self.rnn = nn.GRU(input_size=64,hidden_size=64,num_layers=1,bidirectional=True)\n",
        "    #因为GRU模型使用了双向向量，输出维度加倍\n",
        "    self.f1 = nn.Sequential(nn.Linear(128,64),nn.Dropout(0.8),nn.ReLU())\n",
        "    self.f2 = nn.Sequential(nn.Linear(64,10),nn.Softmax())\n",
        "        \n",
        "  def forward(self,x):\n",
        "    x = self.embedding(x)    \n",
        "    x,_ = self.rnn(x)\n",
        "    x = F.dropout(x,p = 0.8)\n",
        "    #取最后一个时间步的数据\n",
        "    x = self.f1(x[:,-1,:])\n",
        "    return self.f2(x)        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yU3uJu9mvB"
      },
      "source": [
        "# 训练函数\n",
        "def train(x_train,y_train,x_val,y_val):\n",
        "  torch_dataset = Data.TensorDataset(x_train,y_train)\n",
        "  train_loader = DataLoader(dataset=torch_dataset,batch_size=batch_size,shuffle=True,num_workers=3)\n",
        "  # print(train_loader)\n",
        "  cuda = torch.device(\"cuda\")\n",
        "  rnn = TextRNN()\n",
        "  rnn = rnn.cuda()\n",
        "  optimizer = torch.optim.Adam(rnn.parameters(),lr=0.001)\n",
        "  loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "\n",
        "  for i in range(epoch):\n",
        "    for step,(b_x,b_y) in enumerate(train_loader):\n",
        "      #print(step)\n",
        "      b_x = b_x.cuda()\n",
        "      b_y = b_y.cuda()\n",
        "      #print(b_x.detach().cpu().numpy().shape)\n",
        "      output = rnn(b_x)\n",
        "      loss = loss_func(output,b_y)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if step % 500 == 0:\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "        out_val = rnn(x_val)\n",
        "        #print(out_val)\n",
        "        accuracy = np.mean((torch.argmax(out_val,1) == torch.argmax(y_val,1)).cpu().numpy())\n",
        "        print(\"Epoch:{},Step:{},loss:{},accuracy:{}\".format(i,step,loss.item(),accuracy))\n",
        "  return rnn"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz5DhY03qH4Z"
      },
      "source": [
        "#模型测试\n",
        "def test(model,x_test):\n",
        "  x_test = x_test.cuda()\n",
        "  out_test = model(x_test)\n",
        "  #print(out_test)\n",
        "  class_index = torch.max(out_test,1)[1].data.cpu().numpy()\n",
        "  category = [id_to_cate[i] for i in class_index]\n",
        "  print(category[:10])\n",
        "  return category"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZchcAcVSrV-G",
        "outputId": "aad9f143-a6c8-49a1-bb83-4bc2d5d7989a"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "get_train_sample()\n",
        "cates,cate_to_id,id_to_cate = read_cates()\n",
        "words,word_to_id = read_words()\n",
        "print(len(words))\n",
        "#准备训练数据\n",
        "x_train,y_train = process_file(train_file,word_to_id,cate_to_id)\n",
        "x_val,y_val = process_file(val_file,word_to_id,cate_to_id)\n",
        "x_test,y_test = process_file(test_file,word_to_id,cate_to_id)\n",
        "#x_sample,y_sample = process_file(sample_file,word_to_id,cate_to_id)\n",
        "\n",
        "x_train,y_train = torch.LongTensor(x_train),torch.LongTensor(y_train)\n",
        "x_val,y_val = torch.LongTensor(x_val),torch.LongTensor(y_val)\n",
        "x_test,y_test = torch.LongTensor(x_test),torch.LongTensor(y_test)\n",
        "#x_sample,y_sample = torch.LongTensor(x_sample),torch.LongTensor(y_sample)\n",
        "#使用小样本预训练\n",
        "#model = train(x_sample,y_sample,x_val,y_val)\n",
        "# print(y_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "4998\n",
            "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGEaiT7t0TSc",
        "outputId": "2d103664-c29f-4fd7-ff1d-27e50eec18eb"
      },
      "source": [
        "#使用全量数据训练\n",
        "model = train(x_train,y_train,x_val,y_val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0,Step:0,loss:0.7341630458831787,accuracy:0.1056\n",
            "Epoch:1,Step:0,loss:0.7196397185325623,accuracy:0.2904\n",
            "Epoch:2,Step:0,loss:0.7184866666793823,accuracy:0.3162\n",
            "Epoch:3,Step:0,loss:0.7211172580718994,accuracy:0.3208\n",
            "Epoch:4,Step:0,loss:0.7169749140739441,accuracy:0.3284\n",
            "Epoch:5,Step:0,loss:0.7159298658370972,accuracy:0.3348\n",
            "Epoch:6,Step:0,loss:0.7177308201789856,accuracy:0.3318\n",
            "Epoch:7,Step:0,loss:0.7192797660827637,accuracy:0.3346\n",
            "Epoch:8,Step:0,loss:0.7149922847747803,accuracy:0.3352\n",
            "Epoch:9,Step:0,loss:0.7177204489707947,accuracy:0.3378\n",
            "Epoch:10,Step:0,loss:0.7143713235855103,accuracy:0.337\n",
            "Epoch:11,Step:0,loss:0.7150159478187561,accuracy:0.3376\n",
            "Epoch:12,Step:0,loss:0.7142236232757568,accuracy:0.3452\n",
            "Epoch:13,Step:0,loss:0.7191746234893799,accuracy:0.3448\n",
            "Epoch:14,Step:0,loss:0.7102710604667664,accuracy:0.3422\n",
            "Epoch:15,Step:0,loss:0.7114759087562561,accuracy:0.3392\n",
            "Epoch:16,Step:0,loss:0.7175334095954895,accuracy:0.3396\n",
            "Epoch:17,Step:0,loss:0.7117500305175781,accuracy:0.346\n",
            "Epoch:18,Step:0,loss:0.7117784023284912,accuracy:0.3386\n",
            "Epoch:19,Step:0,loss:0.7153165340423584,accuracy:0.345\n",
            "Epoch:20,Step:0,loss:0.715175449848175,accuracy:0.3404\n",
            "Epoch:21,Step:0,loss:0.7158283591270447,accuracy:0.3356\n",
            "Epoch:22,Step:0,loss:0.7122000455856323,accuracy:0.3412\n",
            "Epoch:23,Step:0,loss:0.7117099761962891,accuracy:0.3428\n",
            "Epoch:24,Step:0,loss:0.7152105569839478,accuracy:0.3414\n",
            "Epoch:25,Step:0,loss:0.7172641754150391,accuracy:0.3408\n",
            "Epoch:26,Step:0,loss:0.7149584889411926,accuracy:0.3462\n",
            "Epoch:27,Step:0,loss:0.710892379283905,accuracy:0.3428\n",
            "Epoch:28,Step:0,loss:0.714425802230835,accuracy:0.3424\n",
            "Epoch:29,Step:0,loss:0.7155554294586182,accuracy:0.339\n",
            "Epoch:30,Step:0,loss:0.7150460481643677,accuracy:0.3474\n",
            "Epoch:31,Step:0,loss:0.7099040746688843,accuracy:0.3434\n",
            "Epoch:32,Step:0,loss:0.7171352505683899,accuracy:0.3406\n",
            "Epoch:33,Step:0,loss:0.7103173136711121,accuracy:0.3426\n",
            "Epoch:34,Step:0,loss:0.7091442942619324,accuracy:0.3474\n",
            "Epoch:35,Step:0,loss:0.7162429690361023,accuracy:0.3422\n",
            "Epoch:37,Step:0,loss:0.7131696939468384,accuracy:0.344\n",
            "Epoch:38,Step:0,loss:0.7153007388114929,accuracy:0.3466\n",
            "Epoch:39,Step:0,loss:0.709276020526886,accuracy:0.3458\n",
            "Epoch:40,Step:0,loss:0.7137691974639893,accuracy:0.3488\n",
            "Epoch:41,Step:0,loss:0.7196043133735657,accuracy:0.3488\n",
            "Epoch:42,Step:0,loss:0.7148476839065552,accuracy:0.346\n",
            "Epoch:43,Step:0,loss:0.7144443988800049,accuracy:0.3418\n",
            "Epoch:44,Step:0,loss:0.7164825201034546,accuracy:0.3458\n",
            "Epoch:45,Step:0,loss:0.7162599563598633,accuracy:0.348\n",
            "Epoch:46,Step:0,loss:0.7121662497520447,accuracy:0.3454\n",
            "Epoch:47,Step:0,loss:0.710537850856781,accuracy:0.3486\n",
            "Epoch:48,Step:0,loss:0.7150293588638306,accuracy:0.3466\n",
            "Epoch:49,Step:0,loss:0.7161253094673157,accuracy:0.3484\n",
            "Epoch:50,Step:0,loss:0.7160550355911255,accuracy:0.3462\n",
            "Epoch:51,Step:0,loss:0.7120522856712341,accuracy:0.3492\n",
            "Epoch:52,Step:0,loss:0.7123306393623352,accuracy:0.3488\n",
            "Epoch:53,Step:0,loss:0.7111217379570007,accuracy:0.3486\n",
            "Epoch:54,Step:0,loss:0.7102677822113037,accuracy:0.3486\n",
            "Epoch:55,Step:0,loss:0.711952805519104,accuracy:0.3468\n",
            "Epoch:56,Step:0,loss:0.7116132378578186,accuracy:0.346\n",
            "Epoch:57,Step:0,loss:0.7120574116706848,accuracy:0.3492\n",
            "Epoch:58,Step:0,loss:0.7132456302642822,accuracy:0.3516\n",
            "Epoch:59,Step:0,loss:0.71150141954422,accuracy:0.349\n",
            "Epoch:60,Step:0,loss:0.7115730047225952,accuracy:0.351\n",
            "Epoch:61,Step:0,loss:0.7159750461578369,accuracy:0.3484\n",
            "Epoch:62,Step:0,loss:0.7138124108314514,accuracy:0.3476\n",
            "Epoch:63,Step:0,loss:0.7119359374046326,accuracy:0.3488\n",
            "Epoch:64,Step:0,loss:0.7182603478431702,accuracy:0.3482\n",
            "Epoch:65,Step:0,loss:0.7120140194892883,accuracy:0.3512\n",
            "Epoch:66,Step:0,loss:0.7122215628623962,accuracy:0.3474\n",
            "Epoch:67,Step:0,loss:0.7116637229919434,accuracy:0.348\n",
            "Epoch:68,Step:0,loss:0.7133088707923889,accuracy:0.3462\n",
            "Epoch:69,Step:0,loss:0.7148045897483826,accuracy:0.3482\n",
            "Epoch:70,Step:0,loss:0.7135623097419739,accuracy:0.3512\n",
            "Epoch:71,Step:0,loss:0.712590217590332,accuracy:0.3522\n",
            "Epoch:72,Step:0,loss:0.7126339077949524,accuracy:0.3484\n",
            "Epoch:73,Step:0,loss:0.7104343771934509,accuracy:0.351\n",
            "Epoch:74,Step:0,loss:0.7084406018257141,accuracy:0.3508\n",
            "Epoch:75,Step:0,loss:0.7107920050621033,accuracy:0.3486\n",
            "Epoch:76,Step:0,loss:0.7140944004058838,accuracy:0.351\n",
            "Epoch:77,Step:0,loss:0.7137328386306763,accuracy:0.3518\n",
            "Epoch:78,Step:0,loss:0.7166110277175903,accuracy:0.351\n",
            "Epoch:79,Step:0,loss:0.7099065780639648,accuracy:0.3506\n",
            "Epoch:80,Step:0,loss:0.7124724388122559,accuracy:0.3522\n",
            "Epoch:81,Step:0,loss:0.7142351865768433,accuracy:0.3478\n",
            "Epoch:82,Step:0,loss:0.7100337147712708,accuracy:0.3516\n",
            "Epoch:83,Step:0,loss:0.7128454446792603,accuracy:0.347\n",
            "Epoch:84,Step:0,loss:0.7125944495201111,accuracy:0.352\n",
            "Epoch:85,Step:0,loss:0.7124671936035156,accuracy:0.3494\n",
            "Epoch:86,Step:0,loss:0.7158552408218384,accuracy:0.3468\n",
            "Epoch:87,Step:0,loss:0.7081716656684875,accuracy:0.3526\n",
            "Epoch:88,Step:0,loss:0.7115857005119324,accuracy:0.3482\n",
            "Epoch:89,Step:0,loss:0.7156502604484558,accuracy:0.3492\n",
            "Epoch:90,Step:0,loss:0.714373767375946,accuracy:0.3502\n",
            "Epoch:91,Step:0,loss:0.7088339328765869,accuracy:0.3526\n",
            "Epoch:92,Step:0,loss:0.7170674800872803,accuracy:0.3516\n",
            "Epoch:93,Step:0,loss:0.711442232131958,accuracy:0.3494\n",
            "Epoch:94,Step:0,loss:0.7118943333625793,accuracy:0.3496\n",
            "Epoch:95,Step:0,loss:0.7119104862213135,accuracy:0.3478\n",
            "Epoch:96,Step:0,loss:0.7094403505325317,accuracy:0.3518\n",
            "Epoch:97,Step:0,loss:0.715168297290802,accuracy:0.3484\n",
            "Epoch:98,Step:0,loss:0.7093023657798767,accuracy:0.3462\n",
            "Epoch:99,Step:0,loss:0.7111892700195312,accuracy:0.3508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ccckxsZ0kf_",
        "outputId": "88833d9e-72d5-4f91-d2e9-125533ac27d6"
      },
      "source": [
        "#获得预测结果\n",
        "category = test(model,x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['体育', '体育', '体育', '家居', '时政', '体育', '体育', '体育', '体育', '体育']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}